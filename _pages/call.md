---
layout: page
permalink: /submissions/
title: Call for Papers
description:
nav: true
nav_order: 3
---

## Overview

Machine learning models have demonstrated remarkable success across various domains, yet their decision-making processes often remain opaque. This black-box nature limits their adoption in critical applications, including healthcare, finance, and autonomous systems. In sequential decision-making, where models interact with dynamic environments over time, the challenges of interpretability are further amplified. Understanding the internal mechanisms of these models is crucial for ensuring their reliability, fairness, and alignment with human values.

The "Decoding Decisions" workshop aims to advance the field of explainability in machine learning and sequential decision-making by bringing together researchers from diverse backgrounds. We seek to explore novel methodologies for interpreting decisions, evaluating the impact of explanations, and fostering trust in AI-driven decision-making systems. The workshop will focus on three primary objectives: (i) developing theoretical and empirical approaches to improve explainability in sequential decision-making, (ii) introducing new benchmarks and evaluation protocols for assessing the interpretability of AI systems, and (iii) analyzing the societal and ethical implications of explainable decision-making.

## Objectives

While significant progress has been made in explaining predictions from supervised models, the interpretability of sequential decision-making systems remains an open challenge. Most current explainability methods rely on post-hoc interpretations, which may not faithfully represent the underlying model behavior. Additionally, explainability frameworks often focus on static settings, failing to capture the complexities of dynamic and multi-step decision processes.

This workshop aims to address these gaps by:

1. Developing novel interpretability techniques tailored for reinforcement learning, planning, and decision-making under uncertainty.
2. Investigating causal explanations that provide insights into why models take specific actions rather than simply describing their decisions.
3. Examining human-centric explanations that align with cognitive models of decision-making to improve AI-human collaboration.
4. Evaluating the impact of explanations on user trust, usability, and ethical considerations in real-world applications.

## Topics

We invite submissions that explore various aspects of explainability in machine learning and sequential decision-making, including but not limited to:

* Foundations of Explainability in Sequential Decision Making  
  * Theoretical perspectives on interpretability in reinforcement learning and planning  
  * Causal reasoning and counterfactual explanations for decision models  
  * Novel methods for quantifying and evaluating explainability in sequential settings  

* Methods for Improving Explainability in ML and Decision Making  
  * Policy distillation and rule-based approximations for interpretable decision policies  
  * Model-agnostic vs. model-specific explanation techniques for decision-making models  
  * Generating natural language and visual explanations for reinforcement learning agents  
  * Attribution methods for action selection in Markov Decision Processes (MDPs)  

* Explainability Benchmarks and Evaluation  
  * Development of new datasets and evaluation frameworks for explainable sequential models  
  * Comparative studies of existing explainability techniques in decision-making tasks  
  * Human subject studies to assess the effectiveness of different explanation methods  

* Societal and Ethical Considerations  
  * Fairness and bias detection in decision-making processes  
  * Explainability in high-stakes applications (healthcare, finance, autonomous systems)  
  * The role of transparency in aligning AI decisions with human values  
  * Regulatory and policy perspectives on explainability in decision-making systems  

## Important Dates

* **Submission Deadline**: TBD, 11:59 PM (AoE)  
* **Acceptance Notification**: TBD
* **Camera-Ready Deadline**: TBD, 23:59 PM (AoE)  

## Camera-Ready Instructions

TBD

## Submission Details
TBD

## Questions

For any inquiries, please contact us at [explainableml2025@gmail.com](mailto:explainableml2025@gmail.com).

